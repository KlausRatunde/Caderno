{
  "hash": "9849873addd25da449cc8c981f3b5ed6",
  "result": {
    "markdown": "---\ntitle: \"Análises estatísticas - LM e GLM\"\nformat: html\neditor: visual\nmessage: false\nwarning: false\n---\n\n\n# Aula 09 - 15/05/2024\n\n## Pacotes\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-1_99c928cb30078f3cfd417c7e2c25349b'}\n\n```{.r .cell-code}\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(lme4)\nlibrary(Matrix)\nlibrary(car)\nlibrary(performance)\nlibrary(DHARMa)\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(r4pde)\nlibrary(broom)\n```\n:::\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-2_a9fda233f8ef49c41a42ce752505ce4a'}\n\n```{.r .cell-code}\nmilho <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")\nmilho\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 48 × 5\n   hybrid   block method index yield\n   <chr>    <dbl> <chr>  <dbl> <dbl>\n 1 30F53 HX     1 pin     21.1 12920\n 2 30F53 HX     2 pin     21.1  9870\n 3 30F53 HX     3 pin     23.3  8920\n 4 30F53 HX     4 pin     35.6 13120\n 5 30F53 YH     1 pin     21.1 12060\n 6 30F53 YH     2 pin     22.2  7860\n 7 30F53 YH     3 pin     27.3  7410\n 8 30F53 YH     4 pin     27.8 10300\n 9 30K64        1 pin     20   11700\n10 30K64        2 pin     20   10700\n# ℹ 38 more rows\n```\n:::\n:::\n\n\nEste experimento foi delineado em *parcelas subdivididas*. Foram formados 4 blocos. O híbrido foi aleatorizado dentro dos blocos. Temos o fator Híbrido e o fator bloco, que é um fator aleatório. Dentro de cada bloco temos o híbrido, e dentro dos híbridos temos os métodos de aplicação.\n\nTemos duas opções: Lm ou Aov; ou utilizar o modelo misto (um fator fixo e um aleatório neste modelo).\n\n### Visualizar Index\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-3_d646aebdeeea70d061af91b29e19ff87'}\n\n```{.r .cell-code}\nplot1 <- milho |> \n  ggplot(aes(method, index))+\n  geom_jitter(width = 0.1, alpha = 0.2)+\n  facet_wrap( ~ hybrid)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"black\", size = 0.5)+\n  theme_classic()\nplot1\n```\n\n::: {.cell-output-display}\n![](Aula_09_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n## Modelo para parcela subdividida\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-4_f409e8d7363d131ae7f3ee033d1ef29a'}\n\n```{.r .cell-code}\nmilho2 <- milho |> \n  mutate(block = as.factor(block))\n\nmix2 <- lmer(index ~ hybrid*method + block + (1 | block/hybrid), data = milho2)\n\nAnova(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(>Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nNo fator aleatório, colocamos o hibrido dentro do bloco. ( 1 \\| block/hybrid)\n\nComparamos os híbridos nas linhas e os métodos nas colunas.\n\n### Testar as premissas\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-5_9f4702c7609bfd5d9b5682397a5e41b0'}\n\n```{.r .cell-code}\ncheck_normality(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: residuals appear as normally distributed (p = 0.635).\n```\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n```\n:::\n:::\n\n\nNormalidade ok, homogeneidade não atendeu. Procede-se a transformação para raiz quadrada.\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-6_e07cdb3ab40904c16bedb78e60acd685'}\n\n```{.r .cell-code}\nmix2 <- lmer(sqrt(index) ~ hybrid*method + block + (1|block/hybrid), data = milho2)\nmix2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: sqrt(index) ~ hybrid * method + block + (1 | block/hybrid)\n   Data: milho2\nREML criterion at convergence: 72.5662\nRandom effects:\n Groups       Name        Std.Dev.\n hybrid:block (Intercept) 0.4644  \n block        (Intercept) 2.3536  \n Residual                 0.3742  \nNumber of obs: 48, groups:  hybrid:block, 24; block, 4\nFixed Effects:\n              (Intercept)             hybrid30F53 YH  \n                  4.65420                   -0.04446  \n              hybrid30K64               hybrid30S31H  \n                 -0.49224                    1.09866  \n            hybrid30S31YH              hybridBG7049H  \n                  0.63521                   -0.58990  \n               methodsilk                     block2  \n                 -0.05317                    0.06156  \n                   block3                     block4  \n                  0.56679                    0.73537  \nhybrid30F53 YH:methodsilk     hybrid30K64:methodsilk  \n                  0.20604                    0.16534  \n  hybrid30S31H:methodsilk   hybrid30S31YH:methodsilk  \n                 -0.91003                   -0.43778  \n hybridBG7049H:methodsilk  \n                  0.01751  \noptimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 2 lme4 warnings \n```\n:::\n\n```{.r .cell-code}\nAnova(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(>Chisq)   \nhybrid        15.3159  5   0.009095 **\nmethod         3.8886  1   0.048615 * \nblock          0.0718  3   0.994997   \nhybrid:method 13.3812  5   0.020057 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-7_5d84c9bb8cf1c8611bf4bdb951b14ece'}\n\n```{.r .cell-code}\nplot(simulateResiduals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula_09_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula_09_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula_09_files/figure-html/unnamed-chunk-7-3.png){width=672}\n:::\n:::\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-8_5b3bae7d1ed3d201db38b6b76957dd58'}\n\n```{.r .cell-code}\ncheck_normality(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: residuals appear as normally distributed (p = 0.440).\n```\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: Error variance appears to be homoscedastic (p = 0.971).\n```\n:::\n:::\n\n\nDepois de carregar o Emmeans\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-9_86e2bf083d74be8c46c1f75d8aa3ce97'}\n\n```{.r .cell-code}\nmedias_milho <- emmeans(mix2,\n                        ~ hybrid | method,\n                        type = \"response\")\nmedias_milho\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     25.0 12.1 6084     6.84     54.4\n 30F53 YH     24.5 12.0 6084     6.61     53.7\n 30K64        20.3 10.9 6084     4.51     47.4\n 30S31H       37.1 14.8 6084    13.79     71.8\n 30S31YH      31.7 13.7 6084    10.57     64.2\n BG7049H      19.4 10.7 6084     4.10     46.0\n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL\n 30F53 HX     24.4 12.0 6084     6.56     53.6\n 30F53 YH     26.0 12.4 6084     7.42     56.0\n 30K64        21.3 11.2 6084     5.00     48.9\n 30S31H       26.3 12.5 6084     7.57     56.4\n 30S31YH      26.4 12.5 6084     7.62     56.5\n BG7049H      19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n```\n:::\n\n```{.r .cell-code}\nmedias_milho2 <- emmeans(mix2,\n                         ~ method | hybrid,\n                         type = \"response\")\nmedias_milho2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL\n pin        25.0 12.1 6084     6.84     54.4\n silk       24.4 12.0 6084     6.56     53.6\n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL\n pin        24.5 12.0 6084     6.61     53.7\n silk       26.0 12.4 6084     7.42     56.0\n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL\n pin        20.3 10.9 6084     4.51     47.4\n silk       21.3 11.2 6084     5.00     48.9\n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL\n pin        37.1 14.8 6084    13.79     71.8\n silk       26.3 12.5 6084     7.57     56.4\n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL\n pin        31.7 13.7 6084    10.57     64.2\n silk       26.4 12.5 6084     7.62     56.5\n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL\n pin        19.4 10.7 6084     4.10     46.0\n silk       19.1 10.6 6084     3.96     45.6\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n```\n:::\n\n```{.r .cell-code}\ncld(medias_milho2, Letters = letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  a    \n pin        25.0 12.1 6084     6.84     54.4  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  a    \n silk       26.0 12.4 6084     7.42     56.0  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  a    \n silk       21.3 11.2 6084     5.00     48.9  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  a    \n pin        37.1 14.8 6084    13.79     71.8   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  a    \n pin        31.7 13.7 6084    10.57     64.2  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  a    \n pin        19.4 10.7 6084     4.10     46.0  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n:::\n:::\n\n\nInterpretação: significância da anova ou efeitos da interação; Realiza-se o teste de médias se há efeito; Comparamos a diferença dentro dos métodos, e depois, comparamos a diferença entre os métodos dentro dos híbridos.\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-10_860be9f6fd8158a359be15ee03ebc511'}\n\n```{.r .cell-code}\nmix3 <- lmer(sqrt(yield) ~ hybrid*method + block + (1|block/hybrid), data = milho2)\nmix3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: sqrt(yield) ~ hybrid * method + block + (1 | block/hybrid)\n   Data: milho2\nREML criterion at convergence: 228.4958\nRandom effects:\n Groups       Name        Std.Dev.\n hybrid:block (Intercept) 6.804   \n block        (Intercept) 3.381   \n Residual                 3.264   \nNumber of obs: 48, groups:  hybrid:block, 24; block, 4\nFixed Effects:\n              (Intercept)             hybrid30F53 YH  \n                 106.3573                    -8.9894  \n              hybrid30K64               hybrid30S31H  \n                   2.5090                   -15.6047  \n            hybrid30S31YH              hybridBG7049H  \n                 -17.0172                     3.6513  \n               methodsilk                     block2  \n                  -5.8412                    -6.1122  \n                   block3                     block4  \n                  -0.8094                     3.4947  \nhybrid30F53 YH:methodsilk     hybrid30K64:methodsilk  \n                   4.6122                    -0.5245  \n  hybrid30S31H:methodsilk   hybrid30S31YH:methodsilk  \n                  11.5228                     8.2247  \n hybridBG7049H:methodsilk  \n                   9.9231  \noptimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings \n```\n:::\n\n```{.r .cell-code}\nAnova(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(>Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\ncheck_normality(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: residuals appear as normally distributed (p = 0.214).\n```\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: Error variance appears to be homoscedastic (p = 0.686).\n```\n:::\n:::\n\n\n# Regressão linear\n\nTrabalharemos com o conjunto estande. Coluna 1 - tratamento (percentual das sementes inoculadas com o patógeno), Coluna 2 - bloco, Coluna 3 - número de plantas emergidas.\n\nAvalia o número de plantas infectadas pelo patógeno. Avalia a taxa de diminuição do estande com o aumento da inoculação do patógeno. Não são categorias. É uma variável quantitativa.\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-11_a60ccd59e82d7d956d1399a5611145bd'}\n\n```{.r .cell-code}\nestande <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n```\n:::\n\n\nPlotar o gráfico para visualização dos dados.\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-12_1a710a9b3316c7bb0d95d41a3f61c522'}\n\n```{.r .cell-code}\nestande |> \n  ggplot(aes(trat, nplants, color ))+\n  geom_jitter(width = 0.1, alpha = 0.2)+\n  #facet_wrap(~exp)+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"black\", size = 0.5)+\n  theme_classic()+\n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output-display}\n![](Aula_09_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nMostramos biologicamente que há redução do estande de plantas conforme o aumento da inoculação do patógeno. podemos assumir dois modelos: linear simples ou quadrático. Podemos verificar qual modelo se adequa melhor à regressão.\n\n### Regressão linear simples por experimento\n\n## Modelo linear\n\n### Experimento 1\n\nNão rejeita-se a hipótese nula.\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-13_cf9c1594d9612d6aac0c526061eb7c0f'}\n\n```{.r .cell-code}\nexp1 <- estande |> \n  filter(exp == 1)\n\nexp1 |> \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output-display}\n![](Aula_09_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlm1 <- lm(nplants ~ trat,\n          data = exp1)\nsummary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,\tAdjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n```\n:::\n:::\n\n\n### Experimento 2\n\nRejeita-se a hipótese nula\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-14_5758a2464d25fc699b29620aadb5a57d'}\n\n```{.r .cell-code}\nexp2 <- estande |> \n  filter(exp == 2)\n\nexp2 |> \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output-display}\n![](Aula_09_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlm2 <- lm(nplants ~ trat,\n          data = exp2)\nsummary(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,\tAdjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n```\n:::\n:::\n\n\n### Experimento 3\n\nRejeita-se a hipótese nula.\n\nPoderíamos trabalhar com o modelo logarítmico (transformando).\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-15_c75b24f59c94f733642d73d72aa46b98'}\n\n```{.r .cell-code}\nexp3 <- estande |> \n  filter(exp == 3)\n\nexp3 |> \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output-display}\n![](Aula_09_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlm3 <- lm(nplants ~ trat,\n          data = exp3)\nsummary(lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,\tAdjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n```\n:::\n:::\n\n\n### Usando GLM\n\nPodemos atribuir o glm com distribuição normal ou distribuição de poisson (considerando que a distribuição não é normal).\n\n### Experimento 1\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-16_64db90b0270aabd262ada69841eb73e0'}\n\n```{.r .cell-code}\nglm1 <- glm(nplants ~ trat, family = \"gaussian\",\n            data = exp1)\nsummary(glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 224.9751)\n\n    Null deviance: 5330.5  on 23  degrees of freedom\nResidual deviance: 4949.5  on 22  degrees of freedom\nAIC: 202\n\nNumber of Fisher Scoring iterations: 2\n```\n:::\n\n```{.r .cell-code}\nAIC(glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 202.0045\n```\n:::\n:::\n\n\n### Experimento 2\n\nNeste caso, podemos assumir que o modelo linear foi melhor do que o modelo de poisson, devido à diferença de AIC\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-17_f83b8cd319d197c16e78476eb6576a41'}\n\n```{.r .cell-code}\nglm2 <- glm(nplants ~ trat, family = \"gaussian\",\n            data = exp2)\nsummary(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 167.7464)\n\n    Null deviance: 6886.6  on 23  degrees of freedom\nResidual deviance: 3690.4  on 22  degrees of freedom\nAIC: 194.96\n\nNumber of Fisher Scoring iterations: 2\n```\n:::\n\n```{.r .cell-code}\nAIC(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 194.9597\n```\n:::\n\n```{.r .cell-code}\nglm2b <- glm <- glm(nplants ~ trat, family = \"poisson\",\n            data = exp2)\nsummary(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.134189   0.037583 110.003  < 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\nAIC(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 210.2353\n```\n:::\n:::\n\n\n### Experimento 3\n\nModelo linear. O modelo de poisson no exp 3 é melhor do que um modelo linear, comparando os valores de AIC.\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-18_3b27d5e1816473baad194979b49ad6c1'}\n\n```{.r .cell-code}\nglm3 <- glm(nplants ~ trat, family = \"gaussian\",\n            data = exp3)\nsummary(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n```\n:::\n\n```{.r .cell-code}\nAIC(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 185.0449\n```\n:::\n\n```{.r .cell-code}\nglm3b <- glm <- glm(nplants ~ trat, family = \"poisson\",\n            data = exp3)\nsummary(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.571590   0.029539 154.762  < 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\nAIC(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 183.9324\n```\n:::\n:::\n\n\nObs.: O professor alterou o modelo e considerou o experimento como fator aleatório, não como efeito fixo. Ainda assim, a melhor distribuição foi a distribuissão gaussiana (normal) usando um modelo linear generalizado. Como foi feito a seguir:\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-19_f21ab1cbcd3a9f34ef26d36b62f6bf1f'}\n\n```{.r .cell-code}\nglm33 <- glmer(nplants ~ trat + (trat | exp), family = \"gaussian\",\n            data = estande)\nsummary(glm33)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n```\n:::\n\n```{.r .cell-code}\nAIC(glm33)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 592.8402\n```\n:::\n\n```{.r .cell-code}\nglm33b <- glmer(nplants ~ trat + (trat | exp), family = poisson (link = \"log\"),\n            data = estande)\nsummary(glm33b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.223397   0.147793  28.577  < 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n```\n:::\n\n```{.r .cell-code}\nAIC(glm33b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 660.7282\n```\n:::\n:::\n\n\n### Outro exemplo\n\nCarregar o pacote r4pde.\n\nPredizer uma resposta em relação à outra. Duas respostas numéricas contínuas, ajustanto o modelo linear ou não. Muitos estudos diferentes, gráfico geral. A saída dos gráficos mostra que com a ação do fungicida e redução da severidade acontece um incremento de produtividade da soja.\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-20_f80171266198004005801442bd60c851'}\n\n```{.r .cell-code}\nwm <- WhiteMoldSoybean\nwm |> \n  ggplot(aes(inc, yld))+\n  geom_point()+\n  facet_wrap(~ study)+\n  theme_minimal()+\n  geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output-display}\n![](Aula_09_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n### Modelo LMG\n\nO 3299 é a produtividade por ha quando não há controle. O 9,261 indica a redução de produtividade em kg/ha de acordo com o aumento da severidade.\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-21_0d5a61871ad62e04844f67a4f025820c'}\n\n```{.r .cell-code}\nmofo1 <- lm(yld ~ inc,\n            data = wm)\nsummary(mofo1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3299.619     56.451  58.451  < 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,\tAdjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n```\n:::\n:::\n\n\nAgrupando todos os estudos em um único gráfico.\n\n#### Mofo 1\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-22_51e4dc9ff49bf7d522ce5831a590c5e2'}\n\n```{.r .cell-code}\nwm |> \n  ggplot(aes(inc, yld, group = factor(study)))+\n  geom_point()+\n  #facet_wrap(~ study)+\n  theme_minimal()+\n  geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output-display}\n![](Aula_09_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmofo1 <- lm(yld ~ inc,\n            data = wm)\nsummary(mofo1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3299.619     56.451  58.451  < 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,\tAdjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n```\n:::\n:::\n\n\nObs.: Código muito importante para agrupar vários experimentos. Já detalha as médias para cada variável resposta.\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-23_df3af15c16c595d0367cadb1d45ceba1'}\n\n```{.r .cell-code}\nfit_all <- wm |> \n  group_by(study) |> \n  do(tidy(lm(.$yld ~ .$inc), conf.int = TRUE))\nfit_all\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n```\n:::\n:::\n\n\n#### Mofo 2\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-24_e8c20d2b73a260f06eabc90be3de2a88'}\n\n```{.r .cell-code}\nmofo2 <- wm |> \n  group_by(study) |> \n  do(tidy(lm(.$yld ~ .$inc), conf.int = TRUE))\nmofo2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n```\n:::\n\n```{.r .cell-code}\ndf<- mofo2 |> \n  filter(term == \".$inc\")\nmean(df$estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -19.52932\n```\n:::\n\n```{.r .cell-code}\n#Histograma da produtividade quando incidência é 0\nlibrary(cowplot)\np1 <- mofo2 |> \n  filter(term == \"(Intercept)\") |> \n           ggplot(aes(x = estimate))+\n           geom_histogram(bins = 8, color = \"white\", fill = \"gray\")+\n           theme_r4pde()+\n           labs(x = \"Intercept\", y = \"frequency\")\np2 <- mofo2 |> \n  filter(term == \".$inc\") |> \n           ggplot(aes(x = estimate))+\n           geom_histogram(bins = 8, color = \"white\", fill = \"gray\")+\n           theme_r4pde()+\n           labs(x = \"Slopes\", y = \"frequency\")\nlibrary(patchwork)\np1+p2\n```\n\n::: {.cell-output-display}\n![](Aula_09_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n#### Mofo 3\n\nModelo misto.\n\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-25_0ab4515673ec452625eb49c783fce37e'}\n\n```{.r .cell-code}\nmofo3 <- lmer(yld ~ inc + (inc | study), data = wm,\n              REML = F)\nsummary(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n```\n:::\n:::\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-26_46fecd059654fee494c1c145c937e871'}\n\n```{.r .cell-code}\nlibrary(lme4)\nmofo3 <- lmer(yld ~ inc + (inc|study), data = wm, REML = F)\nsummary(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n```\n:::\n\n```{.r .cell-code}\n#Esta estimativa é muito mais confiável\n# Inc do efeito fico sendo -17 é mais confiável, os outros métodos subestimam os valores\n#A incidência está causando uma redução na produtividade de -17kg (à medida que a incidência aumenta, a produtividade diminui em 17kg)\n\nAnova(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yld\n     Chisq Df Pr(>Chisq)    \ninc 141.09  1  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-27_67133c84e215d8ea8cc1eb5a802128b6'}\n\n```{.r .cell-code}\nwm <- WhiteMoldSoybean\n\nwm |> \n  ggplot(aes(inc, yld)) +\n  geom_point() +\n  #facet_wrap(~ study) +\n  theme_minimal() +\n  geom_smooth(method = 'lm', se = T)\n```\n\n::: {.cell-output-display}\n![](Aula_09_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-28_cf7a8fb80882dc5d45a256b31ff056d7'}\n\n```{.r .cell-code}\nmofo1 <-  lm(yld ~ inc, data = wm)\nsummary(mofo1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3299.619     56.451  58.451  < 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,\tAdjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n```\n:::\n:::\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-29_82d626da4796a1c0031ddbc8f2f16985'}\n\n```{.r .cell-code}\nfit_all <- wm |> \n  group_by(study) |> \n  do(tidy(lm(.$yld ~ .$inc), conf.int = T))\nfit_all\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n```\n:::\n:::\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-30_ac1bed9f1d16b29cf49334402cf39707'}\n\n```{.r .cell-code}\nfit_all.interc <- fit_all |> \n  filter(term == \"(Intercept)\")\n\np1 <- fit_all.interc |> \n  ggplot(aes(x = estimate)) +\n  geom_histogram(bins = 8) +\n  theme_clean() +\n  labs(x = 'Intercept')\n\nfit_all.inc <- fit_all |> \n  filter(term == \".$inc\")\n\np2 <- fit_all.inc |> \n  ggplot(aes(x = estimate)) +\n  geom_histogram(bins = 8) +\n  theme_clean() +\n  labs(x = 'Incidence')\n\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](Aula_09_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='Aula_09_cache/html/unnamed-chunk-31_562060e01f38097d1ab00eafb40e2979'}\n\n```{.r .cell-code}\nmofo3 <-  lmer(yld ~ inc + (inc|study), data = wm, REML = F)\n\nsummary(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n```\n:::\n\n```{.r .cell-code}\nAnova(mofo3) # para obter o valor p\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yld\n     Chisq Df Pr(>Chisq)    \ninc 141.09  1  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nconfint(mofo3, method = 'Wald') # para o calcular o IC\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 %     97.5 %\n.sig01              NA         NA\n.sig02              NA         NA\n.sig03              NA         NA\n.sigma              NA         NA\n(Intercept) 3204.43403 3706.43096\ninc          -20.08046  -14.39219\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}